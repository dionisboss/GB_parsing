{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1)Написать приложение, которое собирает основные новости с сайтов news.mail.ru, lenta.ru, yandex.news\n",
    "Для парсинга использовать xpath. Структура данных должна содержать:\n",
    "название источника,\n",
    "наименование новости,\n",
    "ссылку на новость,\n",
    "дата публикации\n",
    "\n",
    "2)Сложить все новости в БД"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "from requests import get\n",
    "from pprint import pprint\n",
    "from pymongo import MongoClient\n",
    "import hashlib\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36'\n",
    "header = {\n",
    "        'User-Agent':user_agent\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Собираем парсеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Парсер яндекса\n",
    "def news_yandex():\n",
    "    response = get('https://yandex.ru/news/',headers = header)\n",
    "    root = html.fromstring(response.text)\n",
    "    items_tables = root.xpath(\"//table//td\")\n",
    "    result = []\n",
    "    #hot news block\n",
    "    info = {}\n",
    "    info['link'] ='https://yandex.ru/'+  root.xpath(\"/html[1]/body[1]/div[3]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[2]/div[1]/div[1]/h2[1]/a[1]/@href\")[0].split('?')[0]\n",
    "    info['name'] = root.xpath(\"/html[1]/body[1]/div[3]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[2]/div[1]/div[1]/h2[1]/a[1]//text()\")[0]\n",
    "    info['source'],info['time_in_news'] = root.xpath(\"/html[1]/body[1]/div[3]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[2]/div[1]/div[2]/div[1]/text()\")[0].rsplit(' ',1)\n",
    "    info['date_scrapped'] = datetime.date(datetime.now()).strftime('%d/%m/%Y')\n",
    "    info['_id'] = hashlib.md5(info['link'].encode()).hexdigest()\n",
    "    result.append(info)\n",
    "    for item in items_tables:\n",
    "        info = {}\n",
    "        info['link'] = 'https://yandex.ru/' + item.xpath(\".//h2[contains(@class, 'story__title')]//@href\")[0].split('?')[0]\n",
    "        info['name'] = item.xpath(\".//h2[contains(@class, 'story__title')]//text()\")\n",
    "        info['source'],info['time_in_news'] = item.xpath(\".//div[contains(@class, 'story__info')]//text()\")[0].rsplit(' ',1)\n",
    "        info['date_scrapped'] = datetime.date(datetime.now()).strftime('%d/%m/%Y')\n",
    "        info['_id'] = hashlib.md5(info['link'].encode()).hexdigest()\n",
    "        result.append(info)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Парсер мейл.ру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Провлаиваемся на страницу новости и забираем от тда источник и время\n",
    "def mail_Parse_source(link):\n",
    "    response = get(link, headers = header)\n",
    "    root = html.fromstring(response.text)\n",
    "    source = root.xpath(\"//a[@class = 'link color_gray breadcrumbs__link']//text()\")[0]\n",
    "    time_in_news = root.xpath(\"//span[contains(@class,'note')]//text()\")[0].split(' ')[0]\n",
    "    return source, time_in_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# на мейо ру соишком много новостей. Я решилбрать первые 5, с картинками\n",
    "def news_Mail():\n",
    "    response = get('https://news.mail.ru/', headers = header)\n",
    "    root = html.fromstring(response.text)\n",
    "    day_news_main = root.xpath(\"//td[@class='daynews__main']\")\n",
    "\n",
    "    result = []\n",
    "    for item in day_news_main:\n",
    "        info = {}\n",
    "        info['link'] = 'https://news.mail.ru' + item.xpath(\".//@href\")[0]\n",
    "        info['name'] = item.xpath(\".//span[contains(@class, 'photo__captions')]//text()\")[0]\n",
    "        info['source'],info['time_in_news'] = mail_Parse_source(link)\n",
    "        info['date_scrapped'] = datetime.date(datetime.now()).strftime('%d/%m/%Y')\n",
    "        info['_id'] = hashlib.md5(info['link'].encode()).hexdigest()\n",
    "        result.append(info)\n",
    "    for item in day_news_item:\n",
    "        info = {}\n",
    "        info['link'] = 'https://news.mail.ru' + item.xpath(\".//@href\")[0]\n",
    "        info['name'] = item.xpath(\".//span[contains(@class, 'photo__captions')]//text()\")[0]\n",
    "        info['source'],info['time_in_news'] = mail_Parse_source(link)\n",
    "        info['date_scrapped'] = datetime.date(datetime.now()).strftime('%d/%m/%Y')\n",
    "        info['_id'] = hashlib.md5(info['link'].encode()).hexdigest()\n",
    "        result.append(info)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lenta_source(link):\n",
    "    response = get(link, headers = header)\n",
    "    root = html.fromstring(response.text)\n",
    "    time_in_news = root.xpath('//div [@class = \"b-topic__content\"]//time/text()')[0].split(',')[0].lstrip(' ')\n",
    "    return time_in_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Лента ру\n",
    "def news_Lenta():\n",
    "    response = get('https://lenta.ru', headers = header)\n",
    "    root = html.fromstring(response.text)\n",
    "    main_news = root.xpath(\"//div[@class='b-yellow-box__wrap']/div[@class = 'item']\")\n",
    "    for item in main_news:\n",
    "        info = {}\n",
    "        if item.xpath(\".//@href\")[0][0]=='/':\n",
    "            info['link'] = 'https://lenta.ru' + item.xpath(\".//@href\")[0]\n",
    "        else:\n",
    "            info['link'] = item.xpath(\".//@href\")[0]\n",
    "        info['name'] = item.xpath(\".//text()\")[0]\n",
    "        info['source'] = \"Lenta\"\n",
    "        try:\n",
    "            info['time_in_news'] = lenta_source(info['link'])\n",
    "        except:\n",
    "            info['time_in_news']= None\n",
    "        info['date_scrapped'] = datetime.date(datetime.now()).strftime('%d/%m/%Y')\n",
    "        info['_id'] = hashlib.md5(info['link'].encode()).hexdigest()\n",
    "        result.append(info)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем все в базу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('127.0.0.1',27017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = client['News']\n",
    "news = db.news\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create func that will get data from all sources\n",
    "def getData():\n",
    "    data = news_yandex()\n",
    "    data+=news_Mail()\n",
    "    data+=news_Lenta()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addData_All(data,db):\n",
    "    count = 0\n",
    "    count2 = 0\n",
    "    for e in data:\n",
    "        try:\n",
    "            db.insert_one(e)\n",
    "            count2+=1\n",
    "        except:\n",
    "            count+=1\n",
    "            continue\n",
    "    print('Done', count,': Duplicates dropped','\\n', count2, 'new values added')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 18 : Duplicates dropped \n",
      " 81 new values added\n"
     ]
    }
   ],
   "source": [
    "addData_All(getData(),news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': '5aeaa99f6c87c221f3bb444661ff742a',\n",
      " 'date_scrapped': '22/04/2020',\n",
      " 'link': 'https://yandex.ru//news/story/Postavki_iPhone_grozyat_snizitsya_na_chetvert_v_tekushhem_kvartale--768e7fdf18bbba1b465d658e3569b5fb',\n",
      " 'name': ['Поставки iPhone грозят снизиться на четверть в текущем квартале'],\n",
      " 'source': '3DNews',\n",
      " 'time_in_news': '12:05'}\n",
      "{'_id': '9e1ef9a270f5717bf7cd7e996fef9cee',\n",
      " 'date_scrapped': '22/04/2020',\n",
      " 'link': 'https://yandex.ru//news/story/AMD_predstavila_chipy_Ryzen_3_3100_i_Ryzen_3_3300X--e5b9e594bdf96a1112ed8a81c1cd018a',\n",
      " 'name': ['AMD представила чипы Ryzen 3 3100 и Ryzen 3 3300X'],\n",
      " 'source': 'Astera',\n",
      " 'time_in_news': '10:26'}\n",
      "{'_id': '57460601b8058a29a373c580fde3c384',\n",
      " 'date_scrapped': '22/04/2020',\n",
      " 'link': 'https://yandex.ru//news/story/Sebastyan_Fettel_otkazalsya_ot_predlozheniya_Ferrari_po_novomu_kontraktu--1ef2dbac024a065bdd6251350aedac0f',\n",
      " 'name': ['Себастьян Феттель отказался от предложения Ferrari по новому '\n",
      "          'контракту'],\n",
      " 'source': 'Autosport.com.ru',\n",
      " 'time_in_news': '11:36'}\n"
     ]
    }
   ],
   "source": [
    "for new in news.find({}).sort('source').limit(3):\n",
    "    pprint(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
